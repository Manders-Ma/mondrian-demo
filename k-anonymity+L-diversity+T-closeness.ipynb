{"cells":[{"cell_type":"markdown","metadata":{"id":"YT5-eHD6ENwr"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"NADy8cUPEMo0"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import math\n","import time\n","import os\n","import sys"]},{"cell_type":"markdown","metadata":{"id":"D5Kw-q71Exyi"},"source":["### Importing the dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1665475636590,"user":{"displayName":"Hao-Chen Ma","userId":"14654013449048412762"},"user_tz":-480},"id":"qVupsJ1FE1Hi","outputId":"5b8587d4-99fb-4d7f-a7ee-370523c0d8ef"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex</th>\n","      <th>Length</th>\n","      <th>Diameter</th>\n","      <th>Height</th>\n","      <th>Whole-weight</th>\n","      <th>Shucked-weight</th>\n","      <th>Viscera-weight</th>\n","      <th>Shell-weight</th>\n","      <th>Rings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>M</td>\n","      <td>0.455</td>\n","      <td>0.365</td>\n","      <td>0.095</td>\n","      <td>0.5140</td>\n","      <td>0.2245</td>\n","      <td>0.1010</td>\n","      <td>0.150</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>M</td>\n","      <td>0.350</td>\n","      <td>0.265</td>\n","      <td>0.090</td>\n","      <td>0.2255</td>\n","      <td>0.0995</td>\n","      <td>0.0485</td>\n","      <td>0.070</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>F</td>\n","      <td>0.530</td>\n","      <td>0.420</td>\n","      <td>0.135</td>\n","      <td>0.6770</td>\n","      <td>0.2565</td>\n","      <td>0.1415</td>\n","      <td>0.210</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>M</td>\n","      <td>0.440</td>\n","      <td>0.365</td>\n","      <td>0.125</td>\n","      <td>0.5160</td>\n","      <td>0.2155</td>\n","      <td>0.1140</td>\n","      <td>0.155</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I</td>\n","      <td>0.330</td>\n","      <td>0.255</td>\n","      <td>0.080</td>\n","      <td>0.2050</td>\n","      <td>0.0895</td>\n","      <td>0.0395</td>\n","      <td>0.055</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Sex  Length  Diameter  Height  Whole-weight  Shucked-weight  Viscera-weight  \\\n","0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n","1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n","2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n","3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n","4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n","\n","   Shell-weight  Rings  \n","0         0.150     15  \n","1         0.070      7  \n","2         0.210      9  \n","3         0.155     10  \n","4         0.055      7  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["names = (\n","    \"Sex\",\n","    \"Length\",\n","    \"Diameter\",\n","    \"Height\",\n","    \"Whole-weight\",\n","    \"Shucked-weight\",\n","    \"Viscera-weight\",\n","    \"Shell-weight\",\n","    \"Rings\"\n",")\n","original_table = pd.read_csv(\"abalone.data\", header=None, names=names)\n","original_table.head()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def reScale(rings):\n","    if rings<=5:\n","        return 0\n","    elif rings<=10:\n","        return 1\n","    elif rings<=15:\n","        return 2\n","    elif rings<=20:\n","        return 3\n","    elif rings<=25:\n","        return 4\n","    elif rings<=30:\n","        return 5\n","    else:\n","        return None\n","original_table.iloc[:,-1] = original_table.iloc[:,-1].apply(reScale)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 1, 2, 3, 4, 5], dtype=int64)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["np.unique(original_table[\"Rings\"].values)"]},{"cell_type":"markdown","metadata":{"id":"Red_Xz4Gs1it"},"source":["### components"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"--pX-npns1iu"},"outputs":[],"source":["def init(data):\n","    \"\"\"\n","    reset global variables\n","    \"\"\"\n","    global QI_DICT, QI_RANGE, QI_ORDER\n","    # static values\n","    QI_DICT = []\n","    QI_ORDER = [list()]*len(names)\n","    QI_RANGE = [0]*len(names)\n","    att_values = []\n","    for i in range(len(names)):\n","        att_values.append(set())\n","        QI_DICT.append(dict())\n","    for record in data.values:\n","        for i in QI_INDEX:\n","            att_values[i].add(record[i])\n","\n","    for i in QI_INDEX:\n","        value_list = list(att_values[i])\n","        value_list = sorted(value_list)\n","        QI_RANGE[i] = value_list[-1] - value_list[0]\n","        QI_ORDER[i] = list(value_list)\n","        for index, qi_value in enumerate(value_list):\n","            QI_DICT[i][qi_value] = index"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"kZnCY3xis1iu"},"outputs":[],"source":["class Partition(object):\n","\n","    \"\"\"\n","    Class for Group (or EC), which is used to keep records\n","    self.member: records in group\n","    self.low: lower point, use index to avoid negative values\n","    self.high: higher point, use index to avoid negative values\n","    self.allow: show if partition can be split on this QI\n","    \"\"\"\n","\n","    def __init__(self, data, low, high):\n","        \"\"\"\n","        split_tuple = (index, low, high)\n","        \"\"\"\n","        self.low = list(low)\n","        self.high = list(high)\n","        self.member = data\n","        self.allow = [1] * len(names)\n","\n","    def add_record(self, record, dim):\n","        \"\"\"\n","        add one record to member\n","        \"\"\"\n","        self.member.append(record)\n","\n","    def add_multiple_record(self, records, dim):\n","        \"\"\"\n","        add multiple records (list) to partition\n","        \"\"\"\n","        for record in records:\n","            self.add_record(record, dim)\n","\n","    def __len__(self):\n","        \"\"\"\n","        return number of records\n","        \"\"\"\n","        return len(self.member)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ufThH_Yhs1iu"},"outputs":[],"source":["def get_normalized_width(partition, dim):\n","    \"\"\"\n","    return Normalized width of partition\n","    similar to NCP\n","    \"\"\"\n","    d_order = QI_ORDER[dim]\n","    width = d_order[partition.high[dim]] - d_order[partition.low[dim]]\n","    if width == QI_RANGE[dim]:\n","        return 1\n","    return width * 1.0 / QI_RANGE[dim]\n","\n","def choose_dimension(partition):\n","    # choose dim with largest norm_width from all attributes.\n","    # norm_width : partition's width / QI_RANGE's width  is belong to zero to one\n","    max_width = -1\n","    max_dim = -1\n","    for dim in QI_INDEX:\n","        if partition.allow[dim] == 0:\n","            continue\n","        norm_width = get_normalized_width(partition, dim)\n","        if norm_width > max_width:\n","            max_width = norm_width\n","            max_dim = dim\n","    return max_dim"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"YkSAeNB0s1iv"},"outputs":[],"source":["def frequency_set(partition, dim):\n","    \"\"\"\n","    get the frequency_set of partition on dim\n","    \"\"\"\n","    frequency = {}\n","    for record in partition.member:\n","        try:\n","            frequency[record[dim]] += 1\n","        except KeyError:\n","            frequency[record[dim]] = 1\n","    return frequency\n","def find_median(partition, dim):\n","    \"\"\"\n","    find the middle of the partition, return split_val, next_val, value_list[0], value_list[-1]\n","    \"\"\"\n","    # use frequency set to get median\n","    frequency = frequency_set(partition, dim)\n","    split_val = ''\n","    next_val = ''\n","    value_list = list(frequency.keys())\n","    value_list = sorted(value_list)\n","    total = sum(frequency.values())\n","    middle = total // 2\n","    if middle < INPUT_K or len(value_list) <= 1:\n","        try:\n","            return '', '', value_list[0], value_list[-1]\n","        except IndexError:\n","            return '', '', '', ''\n","    index = 0\n","    split_index = 0\n","    for i, qi_value in enumerate(value_list):\n","        index += frequency[qi_value]\n","        if index >= middle:\n","            split_val = qi_value\n","            split_index = i\n","            break\n","    else:\n","        print(\"Error: cannot find split_val\")\n","    try:\n","        next_val = value_list[split_index + 1]\n","    except IndexError:\n","        # there is a frequency value in partition\n","        # which can be handle by mid_set\n","        # e.g.[1, 2, 3, 4, 4, 4, 4]\n","        next_val = split_val\n","    return (split_val, next_val, value_list[0], value_list[-1])"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"O0ltHNLss1iv"},"outputs":[],"source":["def lDiversityChecker(partition, l):\n","    # print(\"Run lDiversityChecker()...\")\n","    saValues = []\n","    for record in partition.member:\n","        saValue = record[SA_INDEX]\n","        saValues.append(saValue)\n","    saValues = np.array(saValues)\n","    unique, counts = np.unique(saValues, return_counts=True)\n","    p = counts / np.sum(counts)\n","    return bool(-np.sum(p * np.log10(p))>=np.log10(l))\n","\n","def tClosenessChecker(partition, t):\n","    # print(\"Run tClosenessChecker()...\")\n","    saValues = []\n","    for record in partition.member:\n","        saValue = record[SA_INDEX]\n","        saValues.append(saValue)\n","    # P1\n","    saValues = np.array(saValues)\n","    \n","    unique, counts = np.unique(saValues, return_counts=True)\n","    # partNum : 計算將SA的相異數分配給目前小部分資料的相異數, 得到有幾部分要分\n","    partNum = math.ceil(SA_CLASS_NUM/unique.size)\n","    summation = 0\n","\n","    for index, value in enumerate(SA_CLASS):\n","        summation = summation + abs(value - unique[math.floor(index/partNum)])\n","\n","    return bool((1/SA_CLASS_NUM) * (summation/(SA_CLASS_NUM-1)) <= t)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"yJdwvmKis1iw"},"outputs":[],"source":["def anonymize(partition, k, l, t):\n","    # recursively partition groups until not allowable\n","    allow_count = 0\n","    for i in QI_INDEX:\n","        allow_count += partition.allow[i]\n","    if allow_count == 0:\n","        RESULT.append(partition)\n","        return\n","    \n","    for index in range(allow_count):\n","        # choose attrubite from domain\n","        dim = choose_dimension(partition)\n","        if dim == -1:\n","            print(\"Error: dim=-1\")\n","\n","        (split_val, next_val, low, high) = find_median(partition, dim)\n","        # Update parent low and high\n","        if low != '':\n","            partition.low[dim] = QI_DICT[dim][low]\n","            partition.high[dim] = QI_DICT[dim][high]\n","        if split_val == '' or split_val == next_val:\n","            # cannot split\n","            partition.allow[dim] = 0\n","            continue\n","\n","        # split the group from median\n","        # lhs : low ~ split_val's index\n","        # rhs : next_val's index ~ hign\n","        mid_index = QI_DICT[dim][split_val]\n","        lhs_high = partition.high[:]\n","        rhs_low = partition.low[:]\n","        lhs_high[dim] = mid_index\n","        rhs_low[dim] = QI_DICT[dim][next_val]\n","        lhs = Partition([], partition.low, lhs_high)\n","        rhs = Partition([], rhs_low, partition.high)\n","        \n","        # use QI_DICT's index to split lhs and rhs, not real index.\n","        for record in partition.member:\n","            pos = QI_DICT[dim][record[dim]]\n","            if pos <= mid_index:\n","                # lhs = [low, mean]\n","                lhs.add_record(record, dim)\n","            else:\n","                # rhs = (mean, high]\n","                rhs.add_record(record, dim)\n","        # check is lhs and rhs satisfy k-anonymity\n","        if len(lhs) < k or len(rhs) < k or lDiversityChecker(partition=lhs, l=l)==False or lDiversityChecker(partition=rhs, l=l)==False or tClosenessChecker(partition=lhs, t=t)==False or tClosenessChecker(partition=rhs, t=t)==False:\n","            partition.allow[dim] = 0\n","            continue\n","        # anonymize sub-partition\n","        anonymize(lhs, k, l, t)\n","        anonymize(rhs, k, l, t)\n","        return\n","    RESULT.append(partition)\n","def merge_qi_value(left_value, right_value, connect_str = \"~\"):\n","    if left_value == right_value:\n","        result = f\"{left_value}\"\n","    else:\n","        result = f\"[{left_value}{connect_str}{right_value}]\"\n","    return result"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def mondrian(data, k, l, t):\n","    startTime = time.time() * 1000\n","    init(data)\n","    \"\"\"\n","        low : the first value of QI_ORDER's index\n","        high : the last value of QI_ORDER's index\n","    \"\"\"\n","    low = [0] * len(QI_ORDER)\n","    high = [(len(v) - 1) for v in QI_ORDER]\n","    whole_partition = Partition(data.values, low, high)\n","\n","    # begin mondrian\n","    anonymize(whole_partition, k, l, t)\n","    result = []\n","    for partition in RESULT:\n","        for record in partition.member:\n","            for index in QI_INDEX:\n","                # merge_qi_value like as [15~17].\n","                record[index] = merge_qi_value(QI_ORDER[index][partition.low[index]],\n","                                QI_ORDER[index][partition.high[index]])\n","            result.append(record)\n","    # end mondrian\n","    endTime = time.time() * 1000\n","    totalTime = endTime - startTime\n","    print(f\"@Parameter : k={k}, l={l}, t={t}\")\n","    print(f\"The consumption of time : {round(totalTime)}ms\")\n","    return result"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import StandardScaler\n","\n","def encoder_and_scaler(table):\n","   table_x = table.iloc[:,:-1]\n","   table_y = table.iloc[:,-1].values\n","   table_x = pd.get_dummies(table_x)\n","   sc = StandardScaler()\n","   table_x = sc.fit_transform(table_x.values)\n","   return table_x, table_y\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, recall_score, f1_score\n","# Import models from sklearn\n","from sklearn.svm import SVC\n","from xgboost import XGBClassifier\n","\n","def print_metrics(y_true, preds):\n","   print('Accuracy score: ', format(accuracy_score(y_true, preds)))\n","\n","def train_and_predict(X,y):\n","   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)\n","   # Instantiate a number of our models\n","   svm_mod = SVC()\n","   xg1 = XGBClassifier(verbosity = 0, use_label_encoder=False)\n","\n","   # Fit each of the 4 models\n","   svm_mod.fit(X_train, y_train)\n","   xg1=xg1.fit(X_train, y_train)\n","\n","   svm_y_pred = svm_mod.predict(X_test)\n","   xg1_y_pred = xg1.predict(X_test)\n","\n","   # Print scores\n","   print_metrics(y_test, svm_y_pred)\n","   print_metrics(y_test, xg1_y_pred)\n","   print(\"======================================\")"]},{"cell_type":"markdown","metadata":{"id":"0c5NKA70s1iw"},"source":["### main"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["original table result : \n","\n","Accuracy score:  0.7119617224880382\n","Accuracy score:  0.6813397129186602\n","======================================\n","@Parameter : k=1000, l=0.8, t=0.8\n","The consumption of time : 169ms\n","Accuracy score:  0.6421052631578947\n","Accuracy score:  0.6421052631578947\n","======================================\n"]}],"source":["SA_NAME = \"Rings\"\n","SA_INDEX = 8\n","SA_CLASS = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29]\n","SA_CLASS_NUM = len(SA_CLASS)\n","QI_NAME = [\"Length\", \"Diameter\", \"Height\", \"Whole-weight\", \"Shucked-weight\", \"Viscera-weight\", \"Shell-weight\"]\n","QI_INDEX = [1,2,3,4,5,6,7]\n","QI_LEN = len(QI_INDEX)\n","INPUT_K = 1000\n","INPUT_L = 0.8\n","INPUT_T = 0.8\n","\"\"\"\n","    RESULT : the collection of all partition\n","    QI_RANGE : attribute's maximum value - attribute's minimum value\n","    QI_DICT : To find out sorted value's index. ex : data=[3,7,8] -> QI_DICT={3:0, 7:1, 8:2}.\n","    QI_ORDER : the sorted data without repeat\n","\"\"\"\n","RESULT = []\n","QI_RANGE = []\n","QI_DICT = []\n","QI_ORDER = []\n","\n","print(\"original table result : \\n\")\n","original_x, original_y = encoder_and_scaler(original_table)\n","train_and_predict(original_x, original_y)\n","            \n","\n","\n","result = mondrian(original_table.loc[:,:],INPUT_K, INPUT_L, INPUT_T)\n","released_table = pd.DataFrame(result, columns=names)\n","released_x, released_y = encoder_and_scaler(released_table)\n","train_and_predict(released_x, released_y)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"nIGo1C7ws1iw","outputId":"fdf3e906-db3d-4c5b-ad4d-d2a4680dbe88"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex</th>\n","      <th>Length</th>\n","      <th>Diameter</th>\n","      <th>Height</th>\n","      <th>Whole-weight</th>\n","      <th>Shucked-weight</th>\n","      <th>Viscera-weight</th>\n","      <th>Shell-weight</th>\n","      <th>Rings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>M</td>\n","      <td>[0.075~0.515]</td>\n","      <td>[0.055~0.35]</td>\n","      <td>[0.0~0.18]</td>\n","      <td>[0.002~0.9225]</td>\n","      <td>[0.001~0.495]</td>\n","      <td>[0.0005~0.2075]</td>\n","      <td>[0.0015~0.3505]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I</td>\n","      <td>[0.075~0.515]</td>\n","      <td>[0.055~0.35]</td>\n","      <td>[0.0~0.18]</td>\n","      <td>[0.002~0.9225]</td>\n","      <td>[0.001~0.495]</td>\n","      <td>[0.0005~0.2075]</td>\n","      <td>[0.0015~0.3505]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I</td>\n","      <td>[0.075~0.515]</td>\n","      <td>[0.055~0.35]</td>\n","      <td>[0.0~0.18]</td>\n","      <td>[0.002~0.9225]</td>\n","      <td>[0.001~0.495]</td>\n","      <td>[0.0005~0.2075]</td>\n","      <td>[0.0015~0.3505]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>M</td>\n","      <td>[0.075~0.515]</td>\n","      <td>[0.055~0.35]</td>\n","      <td>[0.0~0.18]</td>\n","      <td>[0.002~0.9225]</td>\n","      <td>[0.001~0.495]</td>\n","      <td>[0.0005~0.2075]</td>\n","      <td>[0.0015~0.3505]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I</td>\n","      <td>[0.075~0.515]</td>\n","      <td>[0.055~0.35]</td>\n","      <td>[0.0~0.18]</td>\n","      <td>[0.002~0.9225]</td>\n","      <td>[0.001~0.495]</td>\n","      <td>[0.0005~0.2075]</td>\n","      <td>[0.0015~0.3505]</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Sex         Length      Diameter      Height    Whole-weight Shucked-weight  \\\n","0   M  [0.075~0.515]  [0.055~0.35]  [0.0~0.18]  [0.002~0.9225]  [0.001~0.495]   \n","1   I  [0.075~0.515]  [0.055~0.35]  [0.0~0.18]  [0.002~0.9225]  [0.001~0.495]   \n","2   I  [0.075~0.515]  [0.055~0.35]  [0.0~0.18]  [0.002~0.9225]  [0.001~0.495]   \n","3   M  [0.075~0.515]  [0.055~0.35]  [0.0~0.18]  [0.002~0.9225]  [0.001~0.495]   \n","4   I  [0.075~0.515]  [0.055~0.35]  [0.0~0.18]  [0.002~0.9225]  [0.001~0.495]   \n","\n","    Viscera-weight     Shell-weight  Rings  \n","0  [0.0005~0.2075]  [0.0015~0.3505]      1  \n","1  [0.0005~0.2075]  [0.0015~0.3505]      1  \n","2  [0.0005~0.2075]  [0.0015~0.3505]      1  \n","3  [0.0005~0.2075]  [0.0015~0.3505]      1  \n","4  [0.0005~0.2075]  [0.0015~0.3505]      1  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["released_table = pd.DataFrame(result, columns=names)\n","released_table.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_d9utb54s1ix"},"outputs":[],"source":["released_table.to_csv(\"k-anonmity+L-Diversity+T-closeness_abalone_data.csv\", index=False)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy score:  0.7119617224880382\n","Accuracy score:  0.6813397129186602\n","======================================\n","Accuracy score:  0.6421052631578947\n","Accuracy score:  0.6421052631578947\n","======================================\n"]}],"source":["train_and_predict(original_x, original_y)\n","train_and_predict(released_x, released_y)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"vscode":{"interpreter":{"hash":"84d884b480cd48d50014c22e85d2133bcbf491048a6850d0696b03bb495b021c"}}},"nbformat":4,"nbformat_minor":0}
